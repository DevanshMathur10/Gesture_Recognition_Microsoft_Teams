{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/point_history_classifier/point_history.csv'\n",
    "model_save_path = 'model/point_history_classifier/point_history_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 16\n",
    "DIMENSION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, LSTM,InputLayer,Reshape,Flatten\n",
    "from keras import Sequential\n",
    "\n",
    "#!Why is it not workinggggggg RAHHHH\n",
    "#? model=Sequential()\n",
    "#? model.add(InputLayer(input_shape=(TIME_STEPS * DIMENSION, )))\n",
    "#? # model.add(Flatten())\n",
    "#? model.add(Reshape((TIME_STEPS,DIMENSION),input_shape=(TIME_STEPS * DIMENSION, )))\n",
    "#? # model.add(Dropout(0.2))\n",
    "#? # model.add(LSTM(64,return_sequences=True,activation='relu',input_shape=[TIME_STEPS,DIMENSION]))\n",
    "#? # model.add(LSTM(128,return_sequences=True,activation='relu'))\n",
    "#? model.add(LSTM(16,activation='relu'))\n",
    "#? # model.add(Dense(64,activation='relu'))\n",
    "#? model.add(Dense(10,activation='relu'))\n",
    "#? model.add(Dense(NUM_CLASSES,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "    Flatten(),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(NUM_CLASSES,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_lstm = True\n",
    "# model = None\n",
    "\n",
    "# if use_lstm:\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "#         tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(10, activation='relu'),\n",
    "#         tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "#     ])\n",
    "# else:\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(24, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(10, activation='relu'),\n",
    "#         tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_18 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,122\n",
      "Trainable params: 1,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/12 [=>............................] - ETA: 3s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 1s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "12/12 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " 1/12 [=>............................] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 4: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "12/12 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 5: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 6: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 7: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "12/12 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 8: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 9: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 10: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 11: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "10/12 [========================>.....] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 12: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 13: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 14: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 15: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "10/12 [========================>.....] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 16: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "11/12 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 17: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      " 7/12 [================>.............] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 18: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 19: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 20: saving model to model/point_history_classifier\\point_history_classifier.hdf5\n",
      "12/12 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202e62632e0>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 613ms/step\n",
      "[nan nan]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "          15       0.00      0.00      0.00     275.0\n",
      "          19       0.00      0.00      0.00     225.0\n",
      "\n",
      "    accuracy                           0.00     500.0\n",
      "   macro avg       0.00      0.00      0.00     500.0\n",
      "weighted avg       0.00      0.00      0.00     500.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_save_path = 'model/point_history_classifier/point_history_classifier.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_71_layer_call_fn, lstm_cell_71_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpxdu8058e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpxdu8058e\\assets\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1268:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\nc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1268:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [343]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)  \u001b[38;5;66;03m# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m converter\u001b[38;5;241m.\u001b[39moptimizations \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mOptimize\u001b[38;5;241m.\u001b[39mDEFAULT]\n\u001b[1;32m----> 4\u001b[0m tflite_quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mopen\u001b[39m(tflite_save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite(tflite_quantized_model)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:930\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:908\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m    907\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m--> 908\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    909\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1339\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1328\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \n\u001b[0;32m   1330\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1339\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_as_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1322\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1318\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1319\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir))\n\u001b[0;32m   1320\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFLiteKerasModelConverterV2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1322\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1324\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1132\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m   1127\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing new converter: If you encounter a problem \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1128\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease file a bug. You can opt-out \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1129\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby setting experimental_new_converter=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Converts model.\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m result \u001b[38;5;241m=\u001b[39m _convert_graphdef(\n\u001b[0;32m   1133\u001b[0m     input_data\u001b[38;5;241m=\u001b[39mgraph_def,\n\u001b[0;32m   1134\u001b[0m     input_tensors\u001b[38;5;241m=\u001b[39minput_tensors,\n\u001b[0;32m   1135\u001b[0m     output_tensors\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs)\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tflite_model(\n\u001b[0;32m   1139\u001b[0m     result, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quant_mode, quant_io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:212\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     report_error_message(\u001b[38;5;28mstr\u001b[39m(converter_error))\n\u001b[1;32m--> 212\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m converter_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m  \u001b[38;5;66;03m# Re-throws the exception.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:794\u001b[0m, in \u001b[0;36mconvert_graphdef\u001b[1;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    792\u001b[0m     model_flags\u001b[38;5;241m.\u001b[39moutput_arrays\u001b[38;5;241m.\u001b[39mappend(util\u001b[38;5;241m.\u001b[39mget_tensor_name(output_tensor))\n\u001b[1;32m--> 794\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_flags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversion_flags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug_info_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_mlir_converter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_mlir_converter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:311\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model_flags_str, conversion_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_data \u001b[38;5;129;01min\u001b[39;00m _metrics_wrapper\u001b[38;5;241m.\u001b[39mretrieve_collected_errors():\n\u001b[0;32m    310\u001b[0m       converter_error\u001b[38;5;241m.\u001b[39mappend_error(error_data)\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converter_error\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_deprecated_conversion_binary(model_flags_str,\n\u001b[0;32m    314\u001b[0m                                          conversion_flags_str, input_data_str,\n\u001b[0;32m    315\u001b[0m                                          debug_info_str)\n",
      "\u001b[1;31mConverterError\u001b[0m: c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1268:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\nc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1268:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
     ]
    }
   ],
   "source": [
    "# モデルを変換(量子化\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 32]), 'shape_signature': array([-1, 32]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 510 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.8643499e-02 1.7121564e-01 1.8804336e-07 2.2132219e-01 3.0290168e-03\n",
      " 3.4740522e-05 4.8657041e-03 1.7682862e-01 1.0381317e-04 4.8980098e-03\n",
      " 7.8490935e-03 5.1522214e-04 2.4228403e-03 1.9061741e-01 2.8671004e-05\n",
      " 1.0813470e-01 1.9079125e-05 1.6078406e-03 2.6700789e-06 2.4872745e-04\n",
      " 3.0173933e-05 5.9396541e-05 2.7557481e-03 4.4761193e-03 8.8285971e-03\n",
      " 5.4848095e-04 9.1381243e-04]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
